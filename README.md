# WWW '26 Prompt Iteration
Here is the result of prompt iteration for each RQ in WWW '26 paper "Enhancing Content Moderation with LLMs: A Reddit Case Study on Evaluating and Refining Human Decisions".

**RQ1 Version1** uses a prompt structure adapted from prior work on content moderation, with task-specific modifications such as explicit JSON output formatting and evaluation instructions. The system message presents subreddit rules as isolated components, requiring the model to evaluate each post against only one rule per interaction. This version achieves an accuracy of 39.7%. We observe that evaluating rules in isolation hinders the modelâ€™s ability to develop a coherent understanding of community guidelines, resulting in high rates of both false positives (incorrectly flagging compliant content) and false negatives (overlooking actual violations). This suggests that a fragmented rule presentation undermines moderation effectiveness. (RQ1_version1.pdf)
